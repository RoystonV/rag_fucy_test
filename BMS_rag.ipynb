{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell_deps_header",
      "metadata": {},
      "source": [
        "## STEP 1 — INSTALL DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_deps",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -q haystack-ai\n",
        "pip install -q \"sentence-transformers>=2.2.0\"\n",
        "pip install -q google-ai-haystack"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_imports_header",
      "metadata": {},
      "source": [
        "## STEP 2 — IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "from haystack.components.embedders import (\n",
        "    SentenceTransformersDocumentEmbedder,\n",
        "    SentenceTransformersTextEmbedder,\n",
        ")\n",
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "from haystack.components.builders import PromptBuilder\n",
        "from haystack_integrations.components.generators.google_ai import GoogleAIGeminiGenerator\n",
        "\n",
        "print(\"Imports complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_setup_header",
      "metadata": {},
      "source": [
        "## STEP 3 — DOCUMENT STORE & EMBEDDER SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "document_store = InMemoryDocumentStore()\n",
        "\n",
        "MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "doc_embedder  = SentenceTransformersDocumentEmbedder(model=MODEL)\n",
        "text_embedder = SentenceTransformersTextEmbedder(model=MODEL)\n",
        "doc_embedder.warm_up()\n",
        "\n",
        "# top_k=50 so broad queries (\"all damage scenarios\") pull sufficient context\n",
        "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=50)\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_ingest_header",
      "metadata": {},
      "source": [
        "## STEP 4 — DATA INGESTION\n",
        "\n",
        "Stores **full** node and edge objects (including `style`) so the LLM can reproduce them exactly.  \n",
        "Only UI-state fields that carry zero semantic value are stripped:  \n",
        "`dragging`, `resizing`, `selected` (boolean interaction states, not data).\n",
        "\n",
        "Everything else — including `style`, `position`, `positionAbsolute`, `height`, `width`,  \n",
        "`isAsset`, `parentId`, `properties`, `markerStart`, `markerEnd` — is preserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_ingest",
      "metadata": {},
      "outputs": [],
      "source": [
        "ITEM_PATH   = \"item_defination.json\"\n",
        "DAMAGE_PATH = \"Damage_scenarios.json\"\n",
        "\n",
        "# Only strip pure interaction-state booleans that carry no semantic value\n",
        "NODE_STRIP = {\"dragging\", \"resizing\", \"selected\"}\n",
        "EDGE_STRIP = {\"selected\"}\n",
        "\n",
        "def clean_node(node):\n",
        "    \"\"\"Strip interaction-state keys only; preserve style and all data fields.\"\"\"\n",
        "    return {k: v for k, v in node.items() if k not in NODE_STRIP}\n",
        "\n",
        "def clean_edge(edge):\n",
        "    \"\"\"Strip interaction-state keys only.\"\"\"\n",
        "    return {k: v for k, v in edge.items() if k not in EDGE_STRIP}\n",
        "\n",
        "docs = []\n",
        "\n",
        "# ===========================================================================\n",
        "# DATASET 1 — item_defination.json\n",
        "# Each node -> 1 Document  |  Each edge -> 1 Document\n",
        "# ===========================================================================\n",
        "with open(ITEM_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    item_data = json.load(f)\n",
        "\n",
        "model_name = item_data[\"Models\"][0][\"name\"] if item_data.get(\"Models\") else \"unknown\"\n",
        "model_id   = item_data[\"Models\"][0][\"_id\"]  if item_data.get(\"Models\") else None\n",
        "\n",
        "item_start = len(docs)\n",
        "for asset in item_data.get(\"Assets\", []):\n",
        "    asset_id = asset.get(\"_id\")\n",
        "    template = asset.get(\"template\", {})\n",
        "\n",
        "    for node in template.get(\"nodes\", []):\n",
        "        cn = clean_node(node)\n",
        "        docs.append(Document(\n",
        "            content=json.dumps(cn, ensure_ascii=False),\n",
        "            meta={\n",
        "                \"source\":     \"item_definition\",\n",
        "                \"type\":       \"node\",\n",
        "                \"model_name\": model_name,\n",
        "                \"model_id\":   model_id,\n",
        "                \"asset_id\":   asset_id,\n",
        "                \"node_id\":    node.get(\"id\"),\n",
        "                \"node_label\": node.get(\"data\", {}).get(\"label\", \"\"),\n",
        "            }\n",
        "        ))\n",
        "\n",
        "    for edge in template.get(\"edges\", []):\n",
        "        ce = clean_edge(edge)\n",
        "        docs.append(Document(\n",
        "            content=json.dumps(ce, ensure_ascii=False),\n",
        "            meta={\n",
        "                \"source\":      \"item_definition\",\n",
        "                \"type\":        \"edge\",\n",
        "                \"model_id\":    model_id,\n",
        "                \"asset_id\":    asset_id,\n",
        "                \"edge_id\":     edge.get(\"id\"),\n",
        "                \"source_node\": edge.get(\"source\"),\n",
        "                \"target_node\": edge.get(\"target\"),\n",
        "            }\n",
        "        ))\n",
        "\n",
        "print(f\"Item Definition  -> {len(docs) - item_start} docs (nodes + edges)\")\n",
        "\n",
        "# ===========================================================================\n",
        "# DATASET 2 — Damage_scenarios.json\n",
        "# Each Derivation -> 1 Document  |  Each Detail -> 1 Document\n",
        "# ===========================================================================\n",
        "with open(DAMAGE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    damage_data = json.load(f)\n",
        "\n",
        "damage_start = len(docs)\n",
        "for ds in damage_data.get(\"Damage_scenarios\", []):\n",
        "    ds_type  = ds.get(\"type\", \"\")\n",
        "    ds_id    = ds.get(\"_id\")\n",
        "    ds_model = ds.get(\"model_id\")\n",
        "\n",
        "    for deriv in ds.get(\"Derivations\", []):\n",
        "        docs.append(Document(\n",
        "            content=json.dumps(deriv, ensure_ascii=False),\n",
        "            meta={\n",
        "                \"source\":    \"damage_scenarios\",\n",
        "                \"type\":      \"derivation\",\n",
        "                \"ds_type\":   ds_type,\n",
        "                \"ds_id\":     ds_id,\n",
        "                \"model_id\":  ds_model,\n",
        "                \"ds_id_ref\": deriv.get(\"id\"),\n",
        "                \"node_id\":   deriv.get(\"nodeId\"),\n",
        "            }\n",
        "        ))\n",
        "\n",
        "    for detail in (ds.get(\"Details\", []) or []):\n",
        "        docs.append(Document(\n",
        "            content=json.dumps(detail, ensure_ascii=False),\n",
        "            meta={\n",
        "                \"source\":   \"damage_scenarios\",\n",
        "                \"type\":     \"detail\",\n",
        "                \"ds_type\":  ds_type,\n",
        "                \"ds_id\":    ds_id,\n",
        "                \"model_id\": ds_model,\n",
        "                \"node_id\":  detail.get(\"nodeId\"),\n",
        "                \"name\":     detail.get(\"Name\") or detail.get(\"name\"),\n",
        "            }\n",
        "        ))\n",
        "\n",
        "print(f\"Damage Scenarios -> {len(docs) - damage_start} docs (derivations + details)\")\n",
        "print(f\"Total            -> {len(docs)} documents\")\n",
        "\n",
        "embedded_docs = doc_embedder.run(documents=docs)[\"documents\"]\n",
        "document_store.write_documents(embedded_docs)\n",
        "print(f\"All {len(embedded_docs)} documents embedded and stored.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_prompt_header",
      "metadata": {},
      "source": [
        "## STEP 5 — PROMPT TEMPLATE (NATURAL LANGUAGE INTERPRETER + NATIVE STRUCTURE MIRROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_prompt",
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are an intelligent JSON data extraction engine for a BMS (Battery Management System) TARA knowledge base.\n",
        "\n",
        "You will receive:\n",
        "1. Context documents — raw JSON objects representing nodes, edges, derivations, and damage details\n",
        "2. A natural language user query\n",
        "\n",
        "YOUR TASK:\n",
        "- Interpret the user's intent from the query\n",
        "- Collect ALL relevant documents from the context that match the query\n",
        "- Return them verbatim inside the appropriate section — DO NOT remap, rename, or restructure any fields\n",
        "- Every field present in the source document MUST appear in the output with its original key and value\n",
        "\n",
        "CRITICAL RULES:\n",
        "- Return ONLY valid JSON — no markdown, no backticks, no explanation\n",
        "- DO NOT rename any key (e.g. keep \"id\" as \"id\", keep \"data\" as \"data\", keep \"position\" as \"position\")\n",
        "- DO NOT invent or hallucinate any values — copy them exactly from the source document\n",
        "- If a source field has a value (even false / 0 / empty string) — include it as-is\n",
        "- If a field is genuinely absent from the source document — omit it entirely (do not write null)\n",
        "- Preserve style, position, positionAbsolute, height, width, isAsset, parentId and all nested objects exactly\n",
        "- The root key must always be \"result\"\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "  \"result\": {\n",
        "    \"query_intent\": \"<one-line description of what you understood the user wants>\",\n",
        "    \"assets\": [ <full verbatim node objects from context that match the query> ],\n",
        "    \"edges\":  [ <full verbatim edge objects from context that match the query> ],\n",
        "    \"damage_scenarios\": [ <full verbatim derivation objects from context that match the query> ],\n",
        "    \"damage_details\":   [ <full verbatim detail objects from context that match the query> ]\n",
        "  }\n",
        "}\n",
        "\n",
        "SECTION SELECTION — include a section only when the query asks for it:\n",
        "- \"assets\" / \"nodes\" / \"components\" in query -> include assets\n",
        "- \"edges\" / \"connections\" / \"links\" in query -> include edges\n",
        "- \"damage scenarios\" / \"derivations\" / \"loss\" in query -> include damage_scenarios\n",
        "- \"details\" / \"cyber losses\" / \"safety\" / \"threats\" in query -> include damage_details\n",
        "- \"properties\" in query -> include assets (properties live inside node objects)\n",
        "- \"all\" / \"everything\" / \"full\" / \"report\" in query -> include ALL four sections\n",
        "- Specific node name in query -> filter all included sections to only that node\n",
        "- Omit sections that are entirely irrelevant to the query\n",
        "\n",
        "CONTEXT DOCUMENTS:\n",
        "{% for document in documents %}\n",
        "{{ document.content }}\n",
        "{% endfor %}\n",
        "\n",
        "USER QUERY:\n",
        "{{ question }}\n",
        "\n",
        "Return ONLY valid JSON starting with {\"result\":. No markdown. No explanation.\n",
        "\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template=template, required_variables=[\"documents\", \"question\"])\n",
        "print(\"Prompt builder configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_llm_header",
      "metadata": {},
      "source": [
        "## STEP 6 — LLM SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_llm",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_KEY_HERE\"  # <- replace with your key\n",
        "\n",
        "generator = GoogleAIGeminiGenerator(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    generation_kwargs={\"temperature\": 0.0}\n",
        ")\n",
        "print(\"Gemini generator initialised.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_pipeline_header",
      "metadata": {},
      "source": [
        "## STEP 7 — BUILD RAG PIPELINE\n",
        "\n",
        "`text_embedder -> retriever (top_k=50) -> prompt_builder -> llm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_pipeline",
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_pipeline = Pipeline()\n",
        "rag_pipeline.add_component(\"text_embedder\",  text_embedder)\n",
        "rag_pipeline.add_component(\"retriever\",      retriever)\n",
        "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
        "rag_pipeline.add_component(\"llm\",            generator)\n",
        "\n",
        "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "rag_pipeline.connect(\"retriever\",               \"prompt_builder.documents\")\n",
        "rag_pipeline.connect(\"prompt_builder\",          \"llm\")\n",
        "\n",
        "print(\"RAG pipeline built.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_query_header",
      "metadata": {},
      "source": [
        "## STEP 8 — SINGLE QUERY (one-shot)\n",
        "\n",
        "Example natural language queries:\n",
        "- `\"give me all damage scenarios assets and properties\"`\n",
        "- `\"what are the cyber loss properties for CellMonitoring\"`\n",
        "- `\"show all nodes and their connections\"`\n",
        "- `\"full report on BatteryPack\"`\n",
        "- `\"list all derivations related to loss of integrity\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_query",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask(query: str, pretty: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Run the RAG pipeline for a natural language query.\n",
        "    Returns the parsed JSON dict and prints a summary.\n",
        "    \"\"\"\n",
        "    result = rag_pipeline.run({\n",
        "        \"text_embedder\":  {\"text\": query},\n",
        "        \"prompt_builder\": {\"question\": query},\n",
        "    })\n",
        "    raw = result[\"llm\"][\"replies\"][0]\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        if pretty:\n",
        "            print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
        "        inner = parsed.get(\"result\", {})\n",
        "        print(f\"\\n[Intent] {inner.get('query_intent', 'n/a')}\")\n",
        "        for section in [\"assets\", \"edges\", \"damage_scenarios\", \"damage_details\"]:\n",
        "            items = inner.get(section)\n",
        "            if items is not None:\n",
        "                print(f\"  {section}: {len(items)} item(s)\")\n",
        "        return parsed\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"[JSON parse error]\", e)\n",
        "        print(raw)\n",
        "        return {}\n",
        "\n",
        "\n",
        "# One-shot example — change query as needed\n",
        "response = ask(\"give me all damage scenarios assets and properties\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_chatbot_header",
      "metadata": {},
      "source": [
        "## STEP 9 — INTERACTIVE CHATBOT\n",
        "\n",
        "Ask anything in natural language. Type `exit` to quit. Type `history` to review past queries.  \n",
        "All responses are stored in `history` as `{query, result}`.\n",
        "\n",
        "**Example queries:**\n",
        "- `give me all damage scenarios assets and properties`\n",
        "- `what edges are connected to CellMonitoring`\n",
        "- `show all cyber loss properties for every node`\n",
        "- `list all derivations related to loss of integrity`\n",
        "- `full report on BatteryPack`\n",
        "- `everything`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_chatbot",
      "metadata": {},
      "outputs": [],
      "source": [
        "history = []\n",
        "\n",
        "print(\"BMS RAG Chatbot — ask anything in natural language.\")\n",
        "print(\"Commands: 'exit' to quit | 'history' to list past queries\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"\\nQuery: \").strip()\n",
        "    except (EOFError, KeyboardInterrupt):\n",
        "        print(\"\\nSession ended.\")\n",
        "        break\n",
        "\n",
        "    if not user_input:\n",
        "        continue\n",
        "\n",
        "    if user_input.lower() in (\"exit\", \"quit\"):\n",
        "        print(\"Goodbye.\")\n",
        "        break\n",
        "\n",
        "    if user_input.lower() == \"history\":\n",
        "        if not history:\n",
        "            print(\"No history yet.\")\n",
        "        else:\n",
        "            for i, h in enumerate(history, 1):\n",
        "                print(f\"  [{i}] {h['query']}\")\n",
        "        continue\n",
        "\n",
        "    print()\n",
        "    parsed = ask(user_input)\n",
        "    if parsed:\n",
        "        history.append({\"query\": user_input, \"result\": parsed})\n",
        "    print(\"-\" * 60)"
      ]
    }
  ]
}